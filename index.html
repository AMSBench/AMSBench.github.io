<!DOCTYPE html>
<html>
<head>
Â  <meta charset="utf-8">
Â  Â  Â  <meta name="description" content="AMSbench: A Comprehensive Benchmark for Evaluating MLLM Capabilities in AMS Circuits.">
Â  <meta property="og:title" content="AMSbench: A Comprehensive Benchmark for Evaluating MLLM Capabilities in AMS Circuits"/>
Â  <meta property="og:description" content="We introduce AMSbench, a comprehensive benchmark to evaluate Multimodal Large Language Models (MLLMs) in the domain of Analog/Mixed-Signal (AMS) circuits, covering perception, analysis, and design."/>
Â  <meta property="og:url" content="URL_OF_THE_WEBSITE"/>
Â  Â  <meta property="og:image" content="static/image/your_banner_image.png" />
Â  <meta property="og:image:width" content="1200"/>
Â  <meta property="og:image:height" content="630"/>


Â  <meta name="twitter:title" content="AMSbench: A Comprehensive Benchmark for Evaluating MLLM Capabilities in AMS Circuits">
Â  <meta name="twitter:description" content="We introduce AMSbench, a comprehensive benchmark to evaluate MLLMs in the domain of AMS circuits, covering perception, analysis, and design.">
Â  Â  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
Â  <meta name="twitter:card" content="summary_large_image">
Â  Â  <meta name="keywords" content="MLLM, Benchmark, Analog Circuits, Mixed-Signal, EDA, Deep Learning">
Â  <meta name="viewport" content="width=device-width, initial-scale=1">


Â  <title>AMSbench: A Comprehensive Benchmark for Evaluating MLLM Capabilities in AMS Circuits</title>
Â  <link rel="icon" type="image/x-icon" href="static/images/logo.png">
Â  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
Â  rel="stylesheet">

Â  <link rel="stylesheet" href="static/css/bulma.min.css">
Â  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
Â  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
Â  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
Â  <link rel="stylesheet"
Â  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
Â  <link rel="stylesheet" href="static/css/index.css">

Â  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
Â  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
Â  <script defer src="static/js/fontawesome.all.min.js"></script>
Â  <script src="static/js/bulma-carousel.min.js"></script>
Â  <script src="static/js/bulma-slider.min.js"></script>
Â  <script src="static/js/index.js"></script>
</head>
<body>


Â  <section class="hero">
Â  Â  <div class="hero-body">
Â  Â  Â  <div class="container is-max-desktop">
Â  Â  Â  Â  <div class="columns is-centered">
Â  Â  Â  Â  Â  <div class="column has-text-centered">
Â  Â  Â  Â  Â  Â  <h1 class="title is-1 publication-title">AMSbench: A Comprehensive Benchmark for Evaluating MLLM Capabilities in AMS Circuits</h1>

Â  Â  Â  Â  Â  Â  <div class="is-size-5 publication-authors">
Â  Â  Â  Â  Â  Â  Â  <span class="author-block">
Â  Â  Â  Â  Â  Â  Â  Â  <a href="https://scholar.google.com/citations?user=m5NipB4AAAAJ&hl=en" target="_blank">Yichen Shi</a><sup>1,4,*</sup>,
Â  Â  Â  Â  Â  Â  Â  </span>
Â  Â  Â  Â  Â  Â  Â  <span class="author-block">
Â  Â  Â  Â  Â  Â  Â  Â  <a href="AUTHOR_LINK_HERE" target="_blank">Ze Zhang</a><sup>4,*</sup>,
Â  Â  Â  Â  Â  Â  Â  </span>
Â  Â  Â  Â  Â  Â  Â  <span class="author-block">
Â  Â  Â  Â  Â  Â  Â  Â  <a href="https://scholar.google.com/citations?user=UDzaFPIAAAAJ&hl=en" target="_blank">Hongyang Wang</a><sup>4,*</sup>,
Â  Â  Â  Â  Â  Â  Â  </span>
Â  Â  Â  Â  Â  Â  Â  <span class="author-block">
Â  Â  Â  Â  Â  Â  Â  Â  <a href="https://scholar.google.com/citations?user=MszI2TAAAAAJ&hl=zh-CN&oi=ao" target="_blank">Zhuofu Tao</a><sup>2</sup>,
Â  Â  Â  Â  Â  	  </span>
Â  	  			<span class="author-block">
Â  	  			  <a href="AUTHOR_LINK_HERE" target="_blank">Zhongyi Li</a><sup>1</sup>,
Â  	  			</span>
Â  	  			<span class="author-block">
Â  	  			  <a href="AUTHOR_LINK_HERE" target="_blank">Bingyu Chen</a><sup>2</sup>,
Â  	  			</span>
Â  	  			<span class="author-block">
Â  	  			  <a href="AUTHOR_LINK_HERE" target="_blank">Yaxin Wang</a><sup>2</sup>,
Â  	  			</span>
Â  	  			<span class="author-block">
Â  	  			  <a href="https://scholar.google.com/citations?user=wU8x220AAAAJ&hl=en" target="_blank">Zhiping Yu</a><sup>3</sup>,
Â  	  			</span>
Â  	  			<span class="author-block">
Â  	  			  <a href="https://scholar.google.com/citations?user=P8suglMAAAAJ&hl=zh-CN&oi=ao" target="_blank">Ting-Jung Lin</a><sup>4,**</sup>,
Â  	  			</span>
Â  	  			<span class="author-block">
Â  	  			  <a href="https://scholar.google.com/citations?user=n_N-PJkAAAAJ&hl=zh-CN" target="_blank">Lei He</a><sup>1,2,4,**</sup>
Â  	  			</span>
Â  	  		  </div>
Â  
Â  	  		  <div class="is-size-5 publication-authors">
Â  	  			<span class="author-block"><sup>1</sup>Shanghai Jiao Tong University</span>
Â  	  			<span class="author-block"><sup>2</sup>University of California, Los Angeles</span>
Â  	  			<span class="author-block"><sup>3</sup>Tsinghua University</span>
Â  	  			<span class="author-block"><sup>4</sup>Eastern Institute of Technology, Ningbo</span>
Â  	  			<span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
Â  	  			<span class="eql-cntrb"><small><br><sup>**</sup>Indicates Corresponding authors</small></span>
Â  	  		  </div>
Â  
Â  	  				<div class="column has-text-centered">
Â  	  				  <div class="publication-links">
Â  	  						  Â  	  						<span class="link-block">
Â  	  						  <a href="https://arxiv.org/abs/2505.24138.pdf" target="_blank"
Â  	  						  class="external-link button is-normal is-rounded is-dark">
Â  	  						  <span class="icon">
Â  	  							  <i class="fas fa-file-pdf"></i>
Â  	  						  </span>
Â  	  						  <span>Paper</span>
Â  	  						</a>
Â  	  					  </span>
Â  	  					  
Â  	  					  Â  	  					  <span class="link-block">
Â  	  						<a href="https://huggingface.co/datasets/wwhhyy/AMSBench" target="_blank"
Â  	  						class="external-link button is-normal is-rounded is-dark">
Â  	  						<span class="icon" style="font-size:18px">ðŸ¤—</span>
Â  	  						<span>Dataset</span>
Â  	  					  </a>
Â  	  					</span>
Â  	  					
Â  
Â  	  					  Â  	  					  <span class="link-block">
Â  	  						<a href="static/pdfs/supplementary_material.pdf" target="_blank"
Â  	  						class="external-link button is-normal is-rounded is-dark">
Â  	  						<span class="icon">
Â  	  							<i class="fas fa-file-pdf"></i>
Â  	  						</span>
Â  	  						<span>Supplementary</span>
Â  	  					  </a>
Â  	  					</span>
Â  
Â  	  				  Â  	  				  <span class="link-block">
Â  	  					<a href="https://github.com/Why0912/AMSBench" target="_blank"
Â  	  					class="external-link button is-normal is-rounded is-dark">
Â  	  					<span class="icon">
Â  	  						<i class="fab fa-github"></i>
Â  	  					</span>
Â  	  					<span>Code</span>
Â  	  				  </a>
Â  	  				</span>
Â  
Â  	  			  Â  	  			  <span class="link-block">
Â  	  				<a href="https://arxiv.org/abs/2505.24138v1" target="_blank"
Â  	  				class="external-link button is-normal is-rounded is-dark">
Â  	  				<span class="icon">
Â  	  					<i class="ai ai-arxiv"></i>
Â  	  				</span>
Â  	  				<span>arXiv</span>
Â  	  			  </a>
Â  	  			</span>
Â  	  			</div>
Â  	  		  </div>
Â  	  		</div>
Â  	  	  </div>
Â  	  	</div>
Â  	  </div>
Â  </section>
Â  
Â  
<section class="hero teaser">
Â  <div class="hero-body" style="padding: 0;">
Â  	<figure class="image is-fullwidth">
Â  	  <img src="static/images/AMSBench_banner.png" alt="AMSbench Teaser"
Â  			 style="width: 60%; height: auto; display: block; margin: 0 auto;">
Â  	</figure>
Â  	<h2 class="subtitle has-text-centered mt-4">
Â  	  AMSbench: A Comprehensive Benchmark for Evaluating MLLM Capabilities in AMS Circuits
Â  	</h2>
Â  </div>
</section>
Â  
Â  
Â  
Â  
Â  
<section class="section">
Â  <div class="container is-max-desktop">
Â  	<h2 class="title is-3">Abstract</h2>
Â  	<div class="content has-text-justified">
Â  	  <p>
Â  		Analog/Mixed-Signal (AMS) circuits play a critical role in the integrated circuit (IC) industry. 
Â  		However, automating AMS circuit design has remained a longstanding challenge due to its difficulty and complexity. 
Â  		Recent advances in Multi-modal Large Language Models (MLLMs) offer promising potential for supporting AMS circuit analysis and design. 
Â  		However, current research typically evaluates MLLMs on isolated tasks within the domain, 
Â  		lacking a comprehensive benchmark that systematically assesses model capabilities across diverse AMS-related challenges.
Â  	  </p>
Â  	  <p>
Â  		To address this gap, we introduce <strong>AMSbench</strong>, a benchmark suite designed to evaluate MLLM performance across critical tasks 
Â  		including circuit schematic perception, circuit analysis, and circuit design. 
Â  		AMSbench comprises approximately 8000 test questions spanning multiple difficulty levels and assesses eight prominent models, 
Â  		encompassing both open-source and proprietary solutions such as Qwen 2.5-VL and Gemini 2.5 Pro.
Â  	  </p>
Â  	  <p>
Â  		Our evaluation highlights significant limitations in current MLLMs, particularly in complex multi-modal reasoning and sophisticated circuit design tasks. 
Â  		These results underscore the necessity of advancing MLLMsâ€™ understanding and effective application of circuit-specific knowledge, 
Â  		thereby narrowing the existing performance gap relative to human expertise and moving toward fully automated AMS circuit design workflows.
Â  		Our data is released at 
Â  		<a href="https://huggingface.co/datasets/wwhhyy/AMSBench" target="_blank">this URL</a>.
Â  	  </p>
Â  	</div>
Â  </div>
</section>
Â  
Â  
<section class="hero is-light is-small">
Â  <div class="hero-body has-text-centered">
Â  	<h1 class="title is-1 mmmu">
Â  	  <span class="mmmu">AMSBench Benchmark</span>
Â  	</h1>
Â  </div>
</section>
Â  
<section class="section">
    <div class="container is-max-desktop">
        <div class="content has-text-justified">
            <h2 class="title is-3 has-text-centered">Benchmark Introduction</h2>
            <p>
                The design of Analog/Mixed-Signal (AMS) circuits is highly dependent on human expertise, and its automation has been a long-standing challenge. Although Multimodal Large Language Models (MLLMs) have achieved breakthroughs in many fields, their application in the AMS domain remains limited, and a comprehensive evaluation framework to systematically measure their capabilities is lacking. To fill this gap, we propose <strong>AMSbench</strong>, the first comprehensive benchmark designed to rigorously evaluate the three core capabilities of MLLMs in the AMS domain: <strong>Perception, Analysis, and Design</strong>.
            </p>
        </div>
    </div>
</section>
Â  
<section class="hero teaser">
    <div class="hero-body">
<div class="container is-max-desktop">
            <h3 class="title is-4 has-text-centered">Evaluation & Findings</h3>
            <p class="has-text-justified">
                We conducted a comprehensive evaluation of eight leading closed-source and open-source models, including GPT-4o, Gemini-2.5-pro, and Qwen2.5-VL. The results show that while some models perform reasonably well on basic tasks, they generally have significant limitations in complex multimodal reasoning and design tasks.
            </p>
            <ul style="margin-top: 1rem; margin-bottom: 1rem;">
                <li><b>Perception:</b> Most models perform reasonably in identifying local connections but struggle to extract a complete circuit netlist. Even the best-performing model, Gemini-2.5-pro, requires substantial modifications to align with the ground truth.</li>
                <li><b>Analysis:</b> Models show potential in analyzing circuit functions but perform poorly when understanding the trade-offs between performance metrics common in the industry, with even GPT-4o achieving only 58% accuracy on this task.</li>
                <li><b>Design:</b> Models perform well on simple circuit designs but struggle with complex and system-level circuits (like SAR-ADCs). Critically, almost all models fail to generate syntactically correct testbenches.</li>
            </ul>
        </div>
Â  	<figure class="image is-fullwidth">
Â  	  <img src="static/images/rada.png" alt="Performance across MLLMs in various tasks."
Â  			 style="width: 40%; height: auto; display: block; margin: 0 auto;">
Â  	</figure>
Â  	<h2 class="subtitle has-text-centered mt-4">
        Radar chart of MLLM performance on 14 sub-tasks.
Â  	</h2>
Â  </div>
</section>
Â  
<section class="hero teaser">
    <div class="hero-body">
<div class="container is-max-desktop">
            <h3 class="title is-4 has-text-centered">Data Collection & Curation</h3>
            <p class="has-text-justified">
                To build a comprehensive benchmark, we collected data from various sources, including academic textbooks, research papers, and industrial commercial circuit datasheets. We used tools like MinerU to convert PDF documents into Markdown format for efficient extraction of visual elements such as circuit diagrams and tables. For circuit diagrams, we utilized the AMSnet tool to accurately convert them into netlists to recover their topology. Additionally, we combined manual annotations from domain experts with the outputs of advanced MLLMs to generate high-quality "circuit schematic-caption" data pairs.
            </p>
        </div>
Â  	<figure class="image is-fullwidth">
Â  	  <img src="static/images/data_collection.png" alt="Details of AMSBench Data Collection."
Â  			 style="width: 40%; height: auto; display: block; margin: 0 auto;">
Â  	</figure>
Â  	<h2 class="subtitle has-text-centered mt-4">
        The data collection and curation pipeline for AMSBench.
Â  	</h2>
Â  </div>
</section>
Â  
<section class="hero teaser">
    <div class="hero-body">
<div class="container is-max-desktop">
            <h3 class="title is-4 has-text-centered">Question Generation & Task Design</h3>
            <p class="has-text-justified">
                The goal of AMSbench is to thoroughly evaluate the potential applications of MLLMs in the AMS circuit domain. We designed tasks covering both Visual Question Answering (VQA) and Textual Question Answering (TQA) formats, including multiple-choice, computational, and open-ended generative questions. To systematically evaluate, we categorized the questions into three difficulty levels (easy, medium, hard) and designed them for different circuit types to simulate the knowledge requirements at different stages, from undergraduate and graduate students to engineers.
            </p>
        </div>
Â  	<figure class="image is-fullwidth">
Â  	  <img src="static/images/question_generation.png" alt="Details of AMSBench Question Generation."
Â  			 style="width: 40%; height: auto; display: block; margin: 0 auto;">
Â  	</figure>
Â  	<h2 class="subtitle has-text-centered mt-4">
        Examples of question generation for perception (left) and analysis (right) tasks.
Â  	</h2>
Â  </div>
</section>
Â  
<section class="hero teaser">
Â  <div class="hero-body">
Â  	<div class="container is-max-desktop">
        <h3 class="title is-4 has-text-centered">Perception Task Results</h3>
        <p class="has-text-justified">
            The perception task aims to evaluate the MLLM's ability to extract netlists from circuit diagrams, which includes component counting, classification, and connection identification. The table below shows the performance of various models on basic perception tasks such as component counting, classification, and location description.
        </p>
    </div>
Â  	<figure class="image is-fullwidth">
Â  	  <img src="static/images/tab_perception.png" alt="Results of AMSBench Perception Task."
Â  			 style="width: 70%; height: auto; display: block; margin: 0 auto;">
Â  	</figure>
Â  	<h2 class="subtitle has-text-centered mt-4">
        Detailed comparison of models across various perception tasks.
Â  	</h2>
Â  </div>
</section>
Â  
<section class="hero teaser">
    <div class="hero-body">
<div class="container is-max-desktop">
            <h3 class="title is-4 has-text-centered">Comprehensive Task Results</h3>
            <p class="has-text-justified">
                The table below further shows the performance of the models on more complex perception tasks, such as connection judgment and topology generation (netlist recognition), as well as on analysis tasks like reasoning, partition identification, and caption generation.
            </p>
        </div>
Â  	<figure class="image is-fullwidth">
Â  	  <img src="static/images/tab_multitask.png" alt="Results of AMSBench various Task."
Â  			 style="width: 70%; height: auto; display: block; margin: 0 auto;">
Â  	</figure>
Â  	<h2 class="subtitle has-text-centered mt-4">
        Model performance on connection recognition and circuit analysis tasks.
Â  	</h2>
Â  </div>
</section>
Â  
<section class="hero teaser">
    <div class="hero-body">
<div class="container is-max-desktop">
            <h3 class="title is-4 has-text-centered">Design Task Results</h3>
            <p class="has-text-justified">
                The design task evaluates whether a model can generate the correct circuit topology (Circuit Design) and the necessary simulation files for performance verification (Testbench Design) based on given specifications. We use pass@k as the evaluation metric.
            </p>
        </div>
Â  	<figure class="image is-fullwidth">
Â  	  <img src="static/images/tab_design_tb.png" alt="Results of AMSBench various Task."
Â  			 style="width: 60%; height: auto; display: block; margin: 0 auto;">
Â  	</figure>
Â  	<h2 class="subtitle has-text-centered mt-4">
        Performance comparison of models on Circuit Design and Testbench Design tasks.
Â  	</h2>
Â  </div>
</section>
Â  
<section class="section">
Â  <div class="columns is-centered has-text-centered">
Â  	<h2 class="title is-1 mmmu">
Â  	  <span class="mmmu">Examples of various tasks</span>
Â  	</h2>
Â  </div>
</section>
Â  
<section class="hero is-small">
Â  <div class="hero-body">
Â  	<div class="container">
Â  	  <div id="results-carousel" class="carousel results-carousel">
Â  	  	<div class="item">
Â  	  	  Â  	  	  <img src="static/images/perception.png" alt="Perception Task Example" style="display: block; margin: 0 auto; max-width: 70%;" />
Â  	  	  <h2 class="subtitle has-text-centered">
Â  	  	  	<b>Perception Task Example:</b> Includes total/type-wise counting, location description, connection judgment, and topology generation.
Â  	  	  </h2>
Â  	  	</div>
Â  	  	<div class="item">
Â  	  	  Â  	  	  <img src="static/images/partition.png" alt="Partition Task Example" style="display: block; margin: 0 auto; max-width: 70%;" />
Â  	  	  <h2 class="subtitle has-text-centered">
Â  	  	  	<b>Partition Task Example:</b> The model must identify all constituent structures in a complex circuit, such as differential pair and Miller compensation.
Â  	  	  </h2>
Â  	  	</div>
Â  	  	<div class="item">
Â  	  	  Â  	  	  <img src="static/images/reasoning.png" alt="Reasoning Task Example" style="display: block; margin: 0 auto; max-width: 70%;" />
Â  	  	  <h2 class="subtitle has-text-centered">
Â  			   <b>Reasoning Task Example:</b> Based on the circuit diagram, the model must explain why it is an operational amplifier.
Â  	  	  </h2>
Â  	  	</div>
Â  	  	<div class="item">
Â  	  	  Â  	  	  <img src="static/images/function.png" alt="Function Task Example" style="display: block; margin: 0 auto; max-width: 70%;" />
Â  	  	  <h2 class="subtitle has-text-centered">
Â  			   <b>Function Task Example:</b> The model must determine the intended function of the given circuit diagram.
Â  	  	  </h2>
Â  	  	</div>
Â  	  </div>
	</div>
  </div>
</section>
Â  
<section class="hero teaser">
    <div class="hero-body">
<div class="container is-max-desktop">
            <h3 class="title is-4 has-text-centered">Data Statistics</h3>
            <p class="has-text-justified">
                The data in AMSbench is carefully designed and balanced in terms of task types and difficulty levels. The left pie chart shows the number of questions and difficulty distribution for various sub-tasks in the perception category (e.g., total counting, type-wise counting, connection identification). The right chart shows the same for the analysis category (e.g., function identification, reasoning, captioning), distributed by the required knowledge level (Undergraduate, Graduate, Engineer).
            </p>
        </div>
Â  	<figure class="image is-fullwidth">
Â  	  <img src="static/images/data.png" alt="Data statistics of AMSBench."
Â  			 style="width: 70%; height: auto; display: block; margin: 0 auto;">
Â  	</figure>
Â  	<h2 class="subtitle has-text-centered mt-4">
        Data statistics pie charts for the Perception Task (left) and Analysis Task (right).
Â  	</h2>
Â  </div>
</section>
Â  
Â  
Â  
Â  
<section class="hero is-small is-light">
Â  <div class="hero-body">
Â  	<div class="container">
Â  	  <h2 class="title">Poster</h2>
Â  
Â  	  <iframe Â src="static/pdfs/AMSbench_full.pdf" width="100%" height="550">
Â  			</iframe>
Â  		  
Â  	</div>
Â    </div>
Â  </section>
Â  
Â  
Â  <section class="section" id="BibTeX">
Â  	<div class="container is-max-desktop content">
Â  	  <h2 class="title">BibTeX</h2>
Â  	  <pre><code>@misc{shi2025amsbenchcomprehensivebenchmarkevaluating,
Â  			title={AMSbench: A Comprehensive Benchmark for Evaluating MLLM Capabilities in AMS Circuits}, 
Â  			author={Yichen Shi and Ze Zhang and Hongyang Wang and Zhuofu Tao and Zhongyi Li and Bingyu Chen and Yaxin Wang and Zhiping Yu and Ting-Jung Lin and Lei He},
Â  			year={2025},
Â  			eprint={2505.24138},
Â  			archivePrefix={arXiv},
Â  			primaryClass={cs.LG},
Â  			url={https://arxiv.org/abs/2505.24138}, 
Â  }</code></pre>
Â  	</div>
</section>
Â  
Â  
Â  <footer class="footer">
Â  <div class="container">
Â  	<div class="columns is-centered">
Â  	  <div class="column is-8">
Â  		<div class="content">
Â  
Â  		  <p>
Â  			This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page.
Â  			You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license" Â href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
Â  			Commons Attribution-ShareAlike 4.0 International License</a>.
Â  		  </p>
Â  
Â  		</div>
Â  	  </div>
Â  	</div>
Â  </div>
</footer>
Â  
Â  
Â  
Â  	Â  
Â  </body>
Â  </html>