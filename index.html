<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>AMSbench: A Comprehensive Benchmark for Evaluating MLLM Capabilities in AMS Circuits</title>
  <link rel="icon" type="image/x-icon" href="static/images/logo.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <head>
    <link rel="stylesheet" href="static/css/index.css">
  
    <style>
      /* * 1. 让下拉菜单固定在右上角，不随页面滚动 
       */
      .custom-sticky-dropdown {
        position: fixed; /* 固定定位，相对于浏览器窗口 */
        top: 20px;       /* 距离窗口顶部20像素 */
        right: 20px;      /* 距离窗口右侧20像素 */
        z-index: 1000;   /* 设置一个很高的层级，确保它在所有内容的上方 */
      }
  
      /* * 2. 让按钮变得更大、更醒目 
       */
      .custom-sticky-dropdown > .navbar-link {
        font-size: 1.4em; /* 增大文字大小 */
        font-weight: bold; /* 文字加粗 */
        color: #fff !important; /* 设置文字颜色为白色 */
        background-color: #3273dc; /* 设置一个醒目的蓝色背景 (Bulma的蓝色) */
        border-radius: 8px; /* 圆角效果 */
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2); /* 添加阴影，增加立体感 */
        padding:20px 40px; /* 增加内边距，让按钮更大 */
        transition: all 0.2s ease-in-out; /* 添加平滑过渡效果 */

        display: flex;                 /* 启用Flexbox布局 */
        justify-content: space-between;/* 让内部元素两端对齐 */
        align-items: center;           /* 垂直居中对齐 */
        gap: 15px;                     /*在文字和图标之间增加固定间距*/
      }
  
      /* 鼠标悬停时，按钮轻微上浮并变亮 */
      .custom-sticky-dropdown:hover > .navbar-link {
        transform: translateY(-2px); /* 向上移动2像素 */
        box-shadow: 0 6px 16px rgba(0, 0, 0, 0.3); /* 阴影变深 */
        background-color: #3e81e2;
      }
  
      /* * 3. 增大图标尺寸并修改颜色
       */
      .custom-sticky-dropdown .fa-angle-down {
        font-size: 1.5em; /* 将图标放大到文字的1.5倍 */
        color: #fff;       /* 确保图标也是白色 */
      }
  
      /* * 4. 隐藏Bulma默认的箭头 (重要)
       */
      .custom-sticky-dropdown > .navbar-link::after {
        display: none;
      }
  
      /* * 5. 美化下拉菜单的样式
       */
      .custom-sticky-dropdown .navbar-dropdown {
        border-radius: 8px; /* 给下拉菜单也加上圆角 */
        box-shadow: 0 8px 16px rgba(0, 0, 0, 0.15); /* 给下拉菜单加阴影 */
        border: none; /* 移除默认边框 */
        top: calc(100%); /* 让下拉菜单和按钮之间有一点点空隙 */
        width: 300px; 
      }
      .custom-sticky-dropdown .navbar-dropdown .navbar-item {
        display: block;

        font-size: 16px; 
        font-weight: bold; 
        white-space: nowrap;      /* 强制文字不换行 */
        overflow: hidden;         /* 隐藏超出容器部分的内容 */
        text-overflow: ellipsis;  /* 将被隐藏的部分显示为省略号(...) */
      }
    </style>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    </head>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>
  <nav class="navbar is-transparent" role="navigation" aria-label="main navigation">
    <div class="navbar-menu">
      <div class="navbar-end">
        <div class="navbar-item has-dropdown is-hoverable custom-sticky-dropdown">
          <a class="navbar-link">
            Our Related Work   
            <span class="icon is-small is-right">
              <i class="fas fa-angle-down" aria-hidden="true"></i>
            </span>
          </a>
  
          <div class="navbar-dropdown is-right">
            <a class="navbar-item" href="https://amsnet2-0.github.io/AMSNet2.0.github.io/" target="_blank">
              AMSnet 2.0: A Large AMS Databasenwith AI Segmentation for Net Detection
            </a>
            <a class="navbar-item" href="https://amsbench.github.io/" target="_blank">
              AMSbench: A Comprehensive Benchmark for Evaluating MLLM Capabilities in AMS Circuits            
            </a>
            <hr class="navbar-divider">
            <div class="navbar-item">
              More content is coming soon...
            </div>
          </div>
        </div>
      </div>
    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">AMSbench: A Comprehensive Benchmark for Evaluating MLLM Capabilities in AMS Circuits</h1>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=m5NipB4AAAAJ&hl=en" target="_blank">Yichen Shi</a><sup>1,4,*</sup>,
              </span>
              <span class="author-block">
                <a href="AUTHOR_LINK_HERE" target="_blank">Ze Zhang</a><sup>4,*</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=UDzaFPIAAAAJ&hl=en" target="_blank">Hongyang Wang</a><sup>4,*</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=MszI2TAAAAAJ&hl=zh-CN&oi=ao" target="_blank">Zhuofu Tao</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="AUTHOR_LINK_HERE" target="_blank">Zhongyi Li</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="AUTHOR_LINK_HERE" target="_blank">Bingyu Chen</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="AUTHOR_LINK_HERE" target="_blank">Yaxin Wang</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=wU8x220AAAAJ&hl=en" target="_blank">Zhiping Yu</a><sup>3</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=P8suglMAAAAJ&hl=zh-CN&oi=ao" target="_blank">Ting-Jung Lin</a><sup>4,**</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=n_N-PJkAAAAJ&hl=zh-CN" target="_blank">Lei He</a><sup>1,2,4,**</sup>
              </span>
            </div>
  
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Shanghai Jiao Tong University</span>
              <span class="author-block"><sup>2</sup>University of California, Los Angeles</span>
              <span class="author-block"><sup>3</sup>Tsinghua University</span>
              <span class="author-block"><sup>4</sup>Eastern Institute of Technology, Ningbo</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
              <span class="eql-cntrb"><small><br><sup>**</sup>Indicates Corresponding authors</small></span>
            </div>
  
                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2505.24138.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>
                      
                    <!-- hugging face link -->
                    <span class="link-block">
                      <a href="https://huggingface.co/datasets/wwhhyy/AMSBench" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon" style="font-size:18px">🤗</span>
                      <span>Dataset</span>
                    </a>
                  </span>
                    

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/Why0912/AMSBench" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2505.24138v1" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="hero-body" style="padding: 0;">
    <figure class="image is-fullwidth">
      <img src="static/images/AMSBench_banner.png" alt="AMSbench Teaser"
           style="width: 60%; height: auto; display: block; margin: 0 auto;">
    </figure>
    <h2 class="subtitle has-text-centered mt-4">
      AMSbench: A Comprehensive Benchmark for Evaluating MLLM Capabilities in AMS Circuits
    </h2>
  </div>
</section>





<!-- 摘要摘要 -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Abstract</h2>
    <div class="content">
      <p>
        Analog/Mixed-Signal (AMS) circuits play a critical role in the integrated circuit (IC) industry. 
        However, automating AMS circuit design has remained a longstanding challenge due to its difficulty and complexity. 
        Recent advances in Multi-modal Large Language Models (MLLMs) offer promising potential for supporting AMS circuit analysis and design. 
        However, current research typically evaluates MLLMs on isolated tasks within the domain, 
        lacking a comprehensive benchmark that systematically assesses model capabilities across diverse AMS-related challenges.
      </p>
      <p>
        To address this gap, we introduce <strong>AMSbench</strong>, a benchmark suite designed to evaluate MLLM performance across critical tasks 
        including circuit schematic perception, circuit analysis, and circuit design. 
        AMSbench comprises approximately 8000 test questions spanning multiple difficulty levels and assesses eight prominent models, 
        encompassing both open-source and proprietary solutions such as Qwen 2.5-VL and Gemini 2.5 Pro.
      </p>
      <p>
        Our evaluation highlights significant limitations in current MLLMs, particularly in complex multi-modal reasoning and sophisticated circuit design tasks. 
        These results underscore the necessity of advancing MLLMs’ understanding and effective application of circuit-specific knowledge, 
        thereby narrowing the existing performance gap relative to human expertise and moving toward fully automated AMS circuit design workflows.
        Our data is released at 
        <a href="https://huggingface.co/datasets/wwhhyy/AMSBench" target="_blank">this URL</a>.
      </p>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h1 class="title is-1 mmmu">
      <span class="mmmu">AMSBench Benchmark</span>
    </h1>
  </div>
</section>


<section class="section compact-section">
    <div class="container is-max-desktop">
        <div class="content has-text-justified" style="margin-bottom: 3rem;">
            <h2 class="title is-3 has-text-centered">Benchmark Introduction</h2>
            <p>
                The design of Analog/Mixed-Signal (AMS) circuits is highly dependent on human expertise, and its automation has been a long-standing challenge. Although Multimodal Large Language Models (MLLMs) have achieved breakthroughs in many fields, their application in the AMS domain remains limited, and a comprehensive evaluation framework to systematically measure their capabilities is lacking. To fill this gap, we propose <strong>AMSbench</strong>, the first comprehensive benchmark designed to rigorously evaluate the three core capabilities of MLLMs in the AMS domain: <strong>Perception, Analysis, and Design</strong>.
            </p>
        </div>

        <div style="margin-bottom: 3rem;">
            <h3 class="title is-4 has-text-centered">Data Collection & Curation</h3>
            <p class="has-text-justified" style="margin-bottom: 1.5rem;">
                To build a comprehensive benchmark, we collected data from various sources, including academic textbooks, research papers, and industrial datasheets. We used tools like MinerU to convert PDFs and AMSnet to generate netlists from schematics. We then combined expert annotations with MLLM outputs to create high-quality "circuit-caption" data pairs.
            </p>
            <figure class="image">
                <img src="static/images/data_collection.png" alt="Data Collection Pipeline" class="results-image" style="width: 80%; height: auto; display: block; margin: 0 auto;">
            </figure>
        </div>

        <div>
            <h3 class="title is-4 has-text-centered">Question Generation & Task Design</h3>
            <p class="has-text-justified" style="margin-bottom: 1.5rem;">
                AMSbench covers both Visual and Textual Question Answering (VQA/TQA) with multiple formats. Questions are tiered into three difficulty levels (Easy, Medium, Hard) to simulate knowledge requirements from undergraduate to professional engineer levels, ensuring a thorough evaluation of model capabilities.
            </p>
            <figure class="image">
                <img src="static/images/question_generation.png" alt="Question Generation Examples" class="results-image" style="width: 80%; height: auto; display: block; margin: 0 auto;">
            </figure>
        </div>
    </div>
    </div>
</section>

<section class="section compact-section">
    <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Evaluation & Findings</h2>
        <div class="columns is-vcentered">
            <div class="column is-6">
                <p class="has-text-justified">
                    We evaluated 8 leading models, including GPT-4o and Gemini-2.5-pro. Our findings reveal significant limitations in current SOTA models, especially in complex reasoning and design.
                </p>
                <ul>
                    <li><b>Perception:</b> Models struggle to extract complete, accurate netlists.</li>
                    <li><b>Analysis:</b> They show potential but fail to grasp key performance trade-offs.</li>
                    <li><b>Design:</b> Performance is poor on complex circuits, and models cannot generate valid testbenches.</li>
                </ul>
            </div>
            <div class="column is-6">
                 <figure class="image">
                    <img src="static/images/rada.png" alt="Model Performance Radar Chart" class="results-image">
                 </figure>
            </div>
        </div>
        <div class="columns" style="margin-top: 2rem;">
            <div class="column"><img src="static/images/tab_perception.png" alt="Perception Task Results" class="results-image"></div>
            <div class="column"><img src="static/images/tab_multitask.png" alt="Interconnect and Analysis Results" class="results-image"></div>
        </div>
        <p class="has-text-justified">
            For Perception Tasks, while models show promise in recognizing local connectivity, their effectiveness deteriorates when performing comprehensive netlist extraction. For instance, Gemini-2.5-pro achieves the best overall results in component classification (94% accuracy), but all models are challenged by the diversity of component types. Even the best-generated netlists require substantial modifications to match the ground truth.
        </p>
        <div class="has-text-centered" style="margin-top: 1rem;">
            <figure class="image" style="max-width: 600px; margin: auto;">
                 <img src="static/images/tab_design_tb.png" alt="Design Task Results" class="results-image">
            </figure>
        </div>
        <p class="has-text-justified">
            For Analysis and Design Tasks, some models can interpret circuit functionalities but often arrive at correct answers through flawed reasoning. A critical weakness is their poor understanding of performance trade-offs, a key skill for engineers, where the top-performing model, GPT-4o, only scored 58%. In design, models like Grok-3 and Claude-Sonnet perform best on simple circuits but fail on complex systems like SAR-ADCs. Crucially, no model could consistently generate syntactically correct testbenches, likely due to a lack of relevant training data.
        </p>
    </div>
</section>

<section class="section compact-section">
    <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Data Statistics</h2>
        <p class="has-text-centered">The benchmark is carefully balanced across tasks and difficulty levels to provide a robust evaluation framework.</p>
        <figure class="image">
            <img src="static/images/data.png" alt="Data Statistics Pie Charts" style="width: 80%; height: auto; display: block; margin: 0 auto;">
        </figure>
        <p class="has-text-justified">AMSbench is composed of approximately 8,000 test questions, with 6,000 for AMS-Perception, 2,000 for AMS-Analysis, and 68 for AMS-Design. The Perception tasks (visualized in the left pie chart) are categorized by difficulty based on component count—simple (<9), medium (9-16), and hard (>16). They cover various sub-tasks like Total Counting, Type-wise Counting, Element Classification, and Topology Generation. The Analysis tasks (right pie chart) are divided by the academic level required: Undergraduate (532 questions), Graduate (625 questions), and Engineer-level (100 questions). These tasks cover areas like Function recognition, Partitioning, Captioning, and Reasoning to test both visual understanding and deep domain knowledge.</p>
    </div>
</section>


<section class="section compact-section">
  <div class="container is-max-desktop">
    <div class="content has-text-justified" style="margin-bottom: 3rem;">
            <h2 class="title is-3 has-text-centered">Examples of various tasks</h2>
        </div>
  	  <div id="results-carousel" class="carousel results-carousel">
  	  	<div class="item has-text-centered">
  	  	  <img src="static/images/perception.png" alt="Perception Task Example" class="carousel-image" />
  	  	  <h2 class="subtitle has-text-centered mt-4">
  	  	  	<b>Perception Task:</b> Includes total/type-wise counting, location description, connection judgment, and topology generation.
  	  	  </h2>
  	  	</div>
  	  	<div class="item has-text-centered">
  	  	  <img src="static/images/partition.png" alt="Partition Task Example" class="carousel-image" />
  	  	  <h2 class="subtitle has-text-centered mt-4">
  	  	  	<b>Partition Task:</b> The model must identify all constituent structures in a complex circuit, such as differential pair and Miller compensation.
  	  	  </h2>
  	  	</div>
  	  	<div class="item has-text-centered">
  	  	  <img src="static/images/reasoning_cut.png" alt="Reasoning Task Example" class="carousel-image" />
  	  	  <h2 class="subtitle has-text-centered mt-4">
  			   <b>Reasoning Task:</b> Based on the circuit diagram, the model must explain why it functions as an operational amplifier.
  	  	  </h2>
  	  	</div>
  	  	<div class="item has-text-centered">
  	  	  <img src="static/images/function_cut.png" alt="Function Task Example" class="carousel-image" />
  	  	  <h2 class="subtitle has-text-centered mt-4">
  			   <b>Function Task:</b> The model must determine the intended function of the given circuit diagram.
  	  	  </h2>
  	  	</div>
  	  </div>
  </div>
</section>


<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Paper</h2>

      <iframe  src="static/pdfs/AMSbench_full.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{shi2025amsbenchcomprehensivebenchmarkevaluating,
        title={AMSbench: A Comprehensive Benchmark for Evaluating MLLM Capabilities in AMS Circuits}, 
        author={Yichen Shi and Ze Zhang and Hongyang Wang and Zhuofu Tao and Zhongyi Li and Bingyu Chen and Yaxin Wang and Zhiping Yu and Ting-Jung Lin and Lei He},
        year={2025},
        eprint={2505.24138},
        archivePrefix={arXiv},
        primaryClass={cs.LG},
        url={https://arxiv.org/abs/2505.24138}, 
  }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
